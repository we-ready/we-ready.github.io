{
    "componentChunkName": "component---src-templates-blog-js",
    "path": "/blog/20210125003_k8s_cluster_setup",
    "result": {"pageContext":{"frontmatter":{"id":"20210125003_k8s_cluster_setup","title":"Kubernetes (k8s) 集群安装部署","subtitle":"在 CentOS 服务器环境下，K8S 一主一从的集群安装","subject":"云原生","author":"Chris Wei","keywords":"kubeadm;k8s集群","tags":"kubernetes;k8s;Ingress;calico;LENS","category":"指导手册","cover":"http://qiniuargus.weready.online/blog/tech_logos.png","created_when":"2021-01-25","updated_when":"2021-01-25","level":200},"excerpt":"# Kubernetes (k8s) 集群…\n","html":"<h1>Kubernetes (k8s) 集群安装部署</h1>\n<h2>环境概述</h2>\n<ul>\n<li>阿里云 (athena) ECS (2C 8G) x2</li>\n<li>CentOS 7.8</li>\n<li>kubernetes 1.18</li>\n<li>[Master Public IP] ([Master Private IP]): k8s-m1 (master)</li>\n<li>[Worker Public IP] ([Worker Private IP]): k8s-w1 (worker)</li>\n</ul>\n<h2>准备工作</h2>\n<h4>检查操作系统版本</h4>\n<pre><code># cat /etc/redhat-release\nCentOS Linux release 7.8.2003 (Core)\n</code></pre>\n<h4>检查并修改机器名称</h4>\n<pre><code># hostname\n# hostnamectl\n# cat /etc/hostname\n</code></pre>\n<pre><code># vi /etc/hostname\n</code></pre>\n<pre><code>k8s-m1\n</code></pre>\n<pre><code># systemctl restart systemd-hostnamed\n</code></pre>\n<pre><code># reboot\n</code></pre>\n<h4>配置集群 hosts (私有地址)</h4>\n<pre><code># vi /etc/hosts\n</code></pre>\n<pre><code>[Master Private IP] k8s-m1\n[Worker Private IP] k8s-w1\n</code></pre>\n<h4>禁用<code>防火墙</code></h4>\n<pre><code># systemctl stop firewalld &#x26;&#x26; systemctl disable firewalld\n# systemctl stop firewalld\n</code></pre>\n<h4>禁用<code>selinux</code></h4>\n<pre><code># setenforce 0\n# sed -i '7s/enforcing/disabled/' /etc/selinux/config\n</code></pre>\n<pre><code># reboot\n</code></pre>\n<h4>创建配置文件（<code>/etc/sysctl.d/k8s.conf</code>）</h4>\n<blockquote>\n<p>创建文件并添加内容</p>\n</blockquote>\n<pre><code># cat >/etc/sysctl.d/k8s.conf &#x3C;&#x3C;EOF\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nEOF\n</code></pre>\n<blockquote>\n<p>执行命令使之生效</p>\n</blockquote>\n<pre><code># modprobe br_netfilter &#x26;&#x26; sysctl -p /etc/sysctl.d/k8s.conf\n</code></pre>\n<h4>安装ipvs</h4>\n<blockquote>\n<p>创建文件并添加内容（保证在节点重启后能自动加载所需模块）</p>\n</blockquote>\n<pre><code># cat > /etc/sysconfig/modules/ipvs.modules &#x3C;&#x3C;EOF\n#!/bin/bash\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack_ipv4\nEOF\n</code></pre>\n<blockquote>\n<p>修改权限以及查看是否已经正确加载所需的内核模块</p>\n</blockquote>\n<pre><code># chmod 755 /etc/sysconfig/modules/ipvs.modules &#x26;&#x26; bash /etc/sysconfig/modules/ipvs.modules\n</code></pre>\n<blockquote>\n<p>查看是否已经正确加载所需的内核模块</p>\n</blockquote>\n<pre><code># lsmod | grep -e ip_vs -e nf_conntrack_ipv4\nnf_conntrack_ipv4      15053  0 \nnf_defrag_ipv4         12729  1 nf_conntrack_ipv4\nip_vs_sh               12688  0 \nip_vs_wrr              12697  0 \nip_vs_rr               12600  0 \nip_vs                 145497  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr\nnf_conntrack          139264  2 ip_vs,nf_conntrack_ipv4\nlibcrc32c              12644  2 ip_vs,nf_conntrack\n</code></pre>\n<blockquote>\n<p>安装 <code>ipset</code> 和 <code>ipvsadm</code> (便于查看 ipvs 的代理规则)</p>\n</blockquote>\n<pre><code># yum -y install ipset ipvsadm\n</code></pre>\n<h4>同步服务器时间</h4>\n<blockquote>\n<p>安装chrony</p>\n</blockquote>\n<pre><code># yum -y install chrony\n</code></pre>\n<blockquote>\n<p>修改同步服务器地址为阿里云</p>\n</blockquote>\n<pre><code># sed -i.bak '3,6d' /etc/chrony.conf &#x26;&#x26; sed -i '3cserver ntp1.aliyun.com iburst' /etc/chrony.conf\n</code></pre>\n<blockquote>\n<p>启动<code>chronyd</code>及加入开机自启</p>\n</blockquote>\n<pre><code># systemctl start chronyd &#x26;&#x26; systemctl enable chronyd\n</code></pre>\n<blockquote>\n<p>查看同步结果</p>\n</blockquote>\n<pre><code># chronyc sources\n</code></pre>\n<h4>关闭<code>swap</code>分区</h4>\n<blockquote>\n<p>手动关闭swap</p>\n</blockquote>\n<pre><code># swapoff -a\n</code></pre>\n<blockquote>\n<p>修改fstab文件，注释swap自动挂载 (!!!!!! 此处有些问题：貌似原文件中并没有这句话，因此这个命令实际并未发生作用 !!!!!!)</p>\n</blockquote>\n<pre><code># sed -i '/^\\/dev\\/mapper\\/centos-swap/c#/dev/mapper/centos-swap swap                    swap    defaults        0 0' /etc/fstab\n</code></pre>\n<blockquote>\n<p>查看swap是否关闭</p>\n</blockquote>\n<pre><code># free -m\n              total        used        free      shared  buff/cache   available\nMem:           7821         123        7395           0         301        7472\nSwap:             0           0           0\n</code></pre>\n<blockquote>\n<p><code>swappiness</code> 参数调整，修改<code>/etc/sysctl.d/k8s.conf</code>添加下面一行</p>\n</blockquote>\n<pre><code># cat >>/etc/sysctl.d/k8s.conf &#x3C;&#x3C;EOF\nvm.swappiness=0\nEOF\n</code></pre>\n<blockquote>\n<p>使配置生效</p>\n</blockquote>\n<pre><code># sysctl -p /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nvm.swappiness = 0\n</code></pre>\n<h2>安装</h2>\n<h4>安装 Docker18.09.9</h4>\n<blockquote>\n<p>安装 <code>yum-utils</code> 命令包，从而可以使用 <code>yum-config-manager</code> 命令</p>\n</blockquote>\n<pre><code>yum -y install yum-utils\n</code></pre>\n<blockquote>\n<p>添加阿里云yum源</p>\n</blockquote>\n<pre><code>yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n</code></pre>\n<blockquote>\n<p>查看可用版本</p>\n</blockquote>\n<pre><code>yum list docker-ce --showduplicates | sort -r\n已加载插件：fastestmirror, langpacks\n可安装的软件包\n * updates: mirrors.aliyun.com\nLoading mirror speeds from cached hostfile\n * extras: mirrors.aliyun.com\ndocker-ce.x86_64            3:19.03.5-3.el7                     docker-ce-stable\ndocker-ce.x86_64            3:19.03.4-3.el7                     docker-ce-stable\n。。。。。。\ndocker-ce.x86_64            3:18.09.9-3.el7                     docker-ce-stable\ndocker-ce.x86_64            3:18.09.8-3.el7                     docker-ce-stable\ndocker-ce.x86_64            3:18.09.7-3.el7                     docker-ce-stable\ndocker-ce.x86_64            3:18.09.6-3.el7                     docker-ce-stable\n。。。。。。\n</code></pre>\n<blockquote>\n<p>安装docker18.09.9</p>\n</blockquote>\n<pre><code>yum -y install docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9\n</code></pre>\n<blockquote>\n<p>启动docker并设置开机自启</p>\n</blockquote>\n<pre><code>systemctl enable docker &#x26;&#x26; systemctl start docker\n</code></pre>\n<blockquote>\n<p>配置阿里云docker镜像加速</p>\n</blockquote>\n<pre><code>cat > /etc/docker/daemon.json &#x3C;&#x3C;-'EOF'\n{\n  \"registry-mirrors\": [\"https://gqk8w9va.mirror.aliyuncs.com\"]\n}\nEOF\n</code></pre>\n<blockquote>\n<p>配置完后重启docker</p>\n</blockquote>\n<pre><code>systemctl restart docker\n</code></pre>\n<blockquote>\n<p>查看加速</p>\n</blockquote>\n<pre><code>docker info\n</code></pre>\n<p>找到Registry Mirrors一行\nRegistry Mirrors:\n<a href=\"https://gqk8w9va.mirror.aliyuncs.com/\">https://gqk8w9va.mirror.aliyuncs.com/</a></p>\n<blockquote>\n<p>查看docker版本</p>\n</blockquote>\n<pre><code>docker version\n\nClient:\n Version:           18.09.9\n API version:       1.39\n Go version:        go1.11.13\n Git commit:        039a7df9ba\n Built:             Wed Sep  4 16:51:21 2019\n OS/Arch:           linux/amd64\n Experimental:      false\n\nServer: Docker Engine - Community\n Engine:\n  Version:          18.09.9\n  API version:      1.39 (minimum version 1.12)\n  Go version:       go1.11.13\n  Git commit:       039a7df\n  Built:            Wed Sep  4 16:22:32 2019\n  OS/Arch:          linux/amd64\n  Experimental:     false\n</code></pre>\n<h4>修改<code>docker Cgroup Driver</code>为<code>systemd</code></h4>\n<blockquote>\n<p>将/usr/lib/systemd/system/docker.service文件中的这一行 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\n修改为 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd\n如果不修改，在添加 worker 节点时可能会碰到如下错误\n[WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\".</p>\n</blockquote>\n<p>Please follow the guide at <a href=\"https://kubernetes.io/docs/setup/cri/\">https://kubernetes.io/docs/setup/cri/</a></p>\n<blockquote>\n<p>使用如下命令修改</p>\n</blockquote>\n<pre><code>sed -i.bak \"s#^ExecStart=/usr/bin/dockerd.*#ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd#g\" /usr/lib/systemd/system/docker.service\n</code></pre>\n<blockquote>\n<p>重启docker</p>\n</blockquote>\n<pre><code>systemctl daemon-reload &#x26;&#x26; systemctl restart docker\n</code></pre>\n<h4>安装<code>Kubeadm</code></h4>\n<blockquote>\n<p>使用阿里云<code>yum</code>源</p>\n</blockquote>\n<pre><code>cat >/etc/yum.repos.d/kubernetes.repo &#x3C;&#x3C;EOF\n[kubernetes]\nname=Kubernetes\nbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg\n        http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n</code></pre>\n<blockquote>\n<p>安装 <code>kubeadm</code>、<code>kubelet</code>、<code>kubectl</code> (阿里云yum源会随官方更新最新版，因此指定版本)</p>\n</blockquote>\n<blockquote>\n<p>安装1.18.4版本</p>\n</blockquote>\n<pre><code>yum -y install kubelet-1.18.4 kubeadm-1.18.4 kubectl-1.18.4\n</code></pre>\n<blockquote>\n<p>查看版本</p>\n</blockquote>\n<pre><code>kubeadm version\n\nkubeadm version: &#x26;version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.18.4\", GitCommit:\"a17149e1a189050796ced469dbd78d380f2ed5ef\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:42:30Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n</code></pre>\n<blockquote>\n<p>设置<code>kubelet</code>开机自启</p>\n</blockquote>\n<pre><code>systemctl enable kubelet\n</code></pre>\n<blockquote>\n<p>设置<code>k8s</code>命令自动补全</p>\n</blockquote>\n<pre><code>yum -y install bash-completion\nsource /usr/share/bash-completion/bash_completion\nsource &#x3C;(kubectl completion bash)\necho \"source &#x3C;(kubectl completion bash)\" >> ~/.bashrc\n</code></pre>\n<h1>初始化集群</h1>\n<h2>初始化 <code>master</code> 节点</h2>\n<h4>配置 <code>kubeadm</code> 初始化文件</h4>\n<pre><code>cat &#x3C;&#x3C;EOF > ./kubeadm-config.yaml\napiVersion: kubeadm.k8s.io/v1beta2\nkind: ClusterConfiguration\nkubernetesVersion: v1.18.3\nimageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers\n\n#master地址\ncontrolPlaneEndpoint: \"[Mater Private IP]:6443\"\t\nnetworking:\n  serviceSubnet: \"10.96.0.0/16\"\t\n\n  #k8s容器组所在的网段\n  podSubnet: \"10.20.0.1/16\"\t\n  dnsDomain: \"cluster.local\"\n\n# 为了让证书包含公网IP，从而允许从外网访问集群\napiServer:\n  certSANs:       #填写所有kube-apiserver节点的hostname、IP、VIP\n  - k8s-m1        #请替换为hostname\n  - [Master Public IP]  #请替换为公网\n  - [Mater Private IP]  #请替换为私网\n  - 10.96.0.1     #不要替换，此IP是API的集群地址，部分服务会用到\n\nEOF\n</code></pre>\n<h4>初始化 <code>master</code></h4>\n<blockquote>\n<p>⚠️如果想要重新初始化，需要执行命令 <code>kubeadm reset -f</code></p>\n</blockquote>\n<blockquote>\n<p><code>kubeadm init --config=kubeadm-config.yaml --upload-certs</code></p>\n</blockquote>\n<pre><code># kubeadm init --config=kubeadm-config.yaml\n\n....\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of control-plane nodes by copying certificate authorities\nand service account keys on each node and then running the following as root:\n\n  kubeadm join [Mater Private IP]:6443 --token xxxxxx.xxxxxxxxxxxxxxxxx \\\n    --discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \\\n    --control-plane \n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join [Mater Private IP]:6443 --token xxxxxx.xxxxxxxxxxxxxxxxx \\\n    --discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \n\n</code></pre>\n<blockquote>\n<p>⚠️ 保存 token sha256</p>\n</blockquote>\n<blockquote>\n<p>拷贝 <code>kubeconfig</code> 文件（这里的路径为 <code>/root</code>）</p>\n</blockquote>\n<pre><code>mkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n</code></pre>\n<h2>初始化 <code>worker</code> 节点</h2>\n<blockquote>\n<p>将master节点上的 <code>$HOME/.kube/config</code> 文件拷贝到 <code>worker</code> 节点对应的文件中</p>\n</blockquote>\n<pre><code>mkdir -p $HOME/.kube \nscp k8s-m1:~/.kube/config $HOME/.kube\nchown $(id -u):$(id -g) $HOME/.kube/config\n</code></pre>\n<blockquote>\n<p>将 <code>worker</code> 节点加入到集群中</p>\n</blockquote>\n<blockquote>\n<p>这里需要用到2.2中初始化master最后生成的token和sha256值</p>\n</blockquote>\n<pre><code>kubeadm join [Mater Private IP]:6443 --token xxxxxx.xxxxxxxxxxxxxxxxx \\\n    --discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \n\n... ...\n\nThis node has joined the cluster:\n* Certificate signing request was sent to apiserver and a response was received.\n* The Kubelet was informed of the new secure connection details.\n\nRun 'kubectl get nodes' on the control-plane to see this node join the cluster.\n</code></pre>\n<blockquote>\n<p>如果忘记了token和sha256值，可以在master节点使用如下命令查看</p>\n</blockquote>\n<pre><code>#kubeadm token list\nTOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION   EXTRA GROUPS\npx979r.mphk9ee5ya8fgy44   20h       2020-03-18T13:49:48+08:00   authentication,signing   &#x3C;none>        system:bootstrappers:kubeadm:default-node-token\n</code></pre>\n<blockquote>\n<p>查看sha256</p>\n</blockquote>\n<pre><code>#openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n</code></pre>\n<blockquote>\n<p>同时查看token和sha256</p>\n</blockquote>\n<pre><code>#kubeadm token create --print-join-command\nkubeadm join 192.168.9.10:6443 --token 9b28zg.oyt0kvvpmtrem4bg     --discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n</code></pre>\n<blockquote>\n<p>master节点查看node（发现状态都是NotReady，因为还没有安装网络插件，这里我们安装calio官方插件文档）</p>\n</blockquote>\n<pre><code>kubectl get nodes\n</code></pre>\n<h2><code>Master</code> 节点安装网络插件calio</h2>\n<blockquote>\n<p>下载文件</p>\n</blockquote>\n<pre><code>wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml\n</code></pre>\n<blockquote>\n<p>因为在上边kubeadm-config.yaml配置文件中指定了容器组IP，所以需要将文件中的<code>625</code>行改为如下：</p>\n</blockquote>\n<pre><code>value: \"10.20.0.1/16\"\n</code></pre>\n<blockquote>\n<p>vi 命令</p>\n</blockquote>\n<pre><code>:set number\n</code></pre>\n<blockquote>\n<p>修改完成后安装calico网络插件</p>\n</blockquote>\n<pre><code>kubectl apply -f calico.yaml\n</code></pre>\n<blockquote>\n<p>安装完成后稍等一会查看pods状态</p>\n</blockquote>\n<pre><code>kubectl get pods -n kube-system\n</code></pre>\n<blockquote>\n<p>查看node状态</p>\n</blockquote>\n<pre><code>kubectl get nodes \n</code></pre>\n<h2>启动 <code>LENS</code></h2>\n<h4>阿里云开通 <code>6443</code> 端口</h4>\n<h4>Lens 添加集群</h4>\n<pre><code>cat ~/.kube/config\n</code></pre>\n<blockquote>\n<p>IP 修改为公网IP</p>\n</blockquote>\n<blockquote>\n<p>修改其中的 <code>context name</code> 和 <code>current-context: kubernetes-admin@kubernetes</code>，换一个有意义的名字，不要用缺省的，会重名冲突</p>\n</blockquote>\n<h4>启用集群的 <code>Metrics</code> Feature</h4>\n<blockquote>\n<p>需要等待一段时间，才能看到集群 Dashboard</p>\n</blockquote>\n<h1>准备镜像</h1>\n<h4>镜像列表</h4>\n<ul>\n<li>registry.cn-beijing.aliyuncs.com/[???]/worker:0.2.0-[???]</li>\n<li>registry.cn-beijing.aliyuncs.com/[???]/service:0.2.0-[???]</li>\n<li>registry.cn-beijing.aliyuncs.com/[???]/frontend:0.2.0-[???]</li>\n<li>rabbitmq:3.8.2-alpine</li>\n<li>postgres:12.1-alpine</li>\n<li>node:12.14.1-alpine</li>\n<li>redis:5.0.7-alpine</li>\n<li>nginx:1.17.6-alpine</li>\n<li>busybox</li>\n</ul>\n<h4>命令 - 登录阿里云镜像服务</h4>\n<pre><code>docker login -u [user name] -p [password] registry.cn-hangzhou.aliyuncs.com\n</code></pre>\n<blockquote>\n<p>可以参考阿里云镜像服务的命令行提示</p>\n</blockquote>\n<h4>命令 - 获取镜像</h4>\n<pre><code>docker pull\n</code></pre>\n<h1>安装 Git</h1>\n<pre><code>yum install git\n</code></pre>\n<h1>获取 Demo 脚本</h1>\n<blockquote>\n<p>git repo of dockerimages</p>\n</blockquote>\n<pre><code>#!/bin/bash\ngit clone --depth=1 https://[user name]:[password]@github.com/YunzhiWei/dockerimages.git\n</code></pre>\n<h1>启动 Ingress</h1>\n<h2>Ingress Controller of Traefik</h2>\n<blockquote>\n<p>切换到 <code>architecture/traefik</code> 目录</p>\n</blockquote>\n<h4>Apply rbac role and role binding</h4>\n<pre><code># kubectl apply -f traefik-rbac.yaml\n# kubectl describe clusterrole traefik-ingress-controller -n kube-system\n</code></pre>\n<h4>Apply daemonset</h4>\n<pre><code>kubectl apply -f traefik-ds-http.yaml\nkubectl get all -n kube-system | grep traefik\n</code></pre>\n<h1>服务器重启后，k8s 重启失败</h1>\n<h2>参考</h2>\n<p><a href=\"https://www.hangge.com/blog/cache/detail_2419.html\">https://www.hangge.com/blog/cache/detail_2419.html</a>\n原文出自：<a href=\"http://www.hangge.com\">www.hangge.com</a>  转载请保留原文链接：<a href=\"https://www.hangge.com/blog/cache/detail_2419.html\">https://www.hangge.com/blog/cache/detail_2419.html</a></p>\n<h2>背景及现象</h2>\n<p>在安装配置好 Kubernetes 后，正常情况下服务器关机重启，kubelet 也会自动启动的。\n但最近配置的一台服务器重启后，输入命令 <code>kubectl get nodes</code> 查看节点报如下错误：\n<code>The connection to the server xxx.xxx.xxx.xxx:6443 was refused - did you specify the right host or port?</code></p>\n<h2>检查</h2>\n<p>输入 <code>systemctl status kubelet</code> 命令查看 <code>kubelet</code> 的情况</p>\n<blockquote>\n<p>发现 kubelet 确实没有启动</p>\n</blockquote>\n<pre><code>... ...\ncode=exited, status=255\n... ...\n</code></pre>\n<h2>原因</h2>\n<p>由于 K8s 必须保持全程关闭交换内存，之前我安装是只是使用 swapoff -a 命令暂时关闭 swap。而机器重启后，swap 还是会自动启用，从而导致 kubelet 无法启动。</p>\n<h2>解决办法</h2>\n<h4>首先，执行如下命令关闭 swap</h4>\n<pre><code>swapoff -a\n</code></pre>\n<h4>然后，编辑 /etc/fstab 文件</h4>\n<pre><code>vi /etc/fstab\n</code></pre>\n<p>将 <code>/dev/mapper/centos-swap swap swap default 0 0</code> 这一行前面加个 <code>#</code> 号将其注释掉。</p>\n<h2>重启服务器</h2>\n<h1>执行 kubectl 命令报错：证书过期</h1>\n<h2>错误提示</h2>\n<blockquote>\n<p><code>Unable to connect to the server: x509: certificate has expired or is not yet valid</code></p>\n</blockquote>\n<h2>参考</h2>\n<h4><a href=\"https://q.cnblogs.com/q/133037/\">k8s master 出现问题证书过期问题</a></h4>\n<pre><code>经过实际验证，解决方法非常简单，只需运行2个命令：\n\n1）更新所有证书\n\nkubeadm alpha certs renew all\n\n2）更新当前用户的 .kube/config\n\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n注：如果少了第2步，运行 kubectl 命令时会报错\n\nerror: You must be logged in to the server (Unauthorized)\n</code></pre>\n<h4><a href=\"https://www.cnblogs.com/kuku0223/p/11867391.html\">kubernets 证书过期的问题</a></h4>\n<blockquote>\n<p>原理及预防（似乎版本过老，稳重用的命令<code>kubeadm alpha phase certs</code>，已经改成了<code>kubeadm alpha certs</code>）</p>\n</blockquote>\n<pre><code>kubeadm 是 kubernetes 提供的一个初始化集群的工具，使用起来非常方便。但是它创建的apiserver、controller-manager等证书默认只有一年的有效期，同时kubelet 证书也只有一年有效期，一年之后 kubernetes 将停止服务。\n官方推荐一年之内至少用 kubeadm upgrade 更新一次 kubernetes 系统，更新时也会自动更新证书。不过，在产线环境或者无法连接外网的环境频繁更新 kubernetes 不太现实。\n我们可以在过期之前或之后，使用kubeadm alpha phase里的certs和kubeconfig命令，同时配合kubelet证书自动轮换机制来解决这个问题。\n</code></pre>\n<blockquote>\n<p>操作注意事项</p>\n</blockquote>\n<pre><code>一旦证书过期，使用kubectl时会出现如下提示：\nUnable to connect to the server: x509: certificate has expired or is not yet valid\n在此，我们使用 kubeadm alpha phase certs 系统命令，重新生成证书。\n建议不要重新生成ca证书，因为更新了ca证书，集群节点就需要手工操作，才能让集群正常(会涉及重新join)。\n\n操作之前，先将/etc/kubernetes/pki下的证书文件，mv到其它文件夹，作个临时备份，不要删除。\n\nkubeadm alpha phase certs etcd-healthcheck-client --config cluster.yaml\nkubeadm alpha phase certs etcd-peer --config cluster.yaml\nkubeadm alpha phase certs etcd-server --config cluster.yaml\nkubeadm alpha phase certs front-proxy-client--config cluster.yaml\nkubeadm alpha phase certs apiserver-etcd-client --config cluster.yaml\nkubeadm alpha phase certs apiserver-kubelet-client --config cluster.yaml\nkubeadm alpha phase certs apiserver --config cluster.yaml\nkubeadm alpha phase certs sa --config cluster.yaml\n\n\n在生成这些新的证书文件之后，再需要kubeadm alpha phase config命令，重新生成新的kubeconfig文件。\n操作之前，先将/etc/kubernetes/下的kubeconfig，mv到其它文件夹，作个临时备份，不要删除。\nkubeadm alpha phase kubeconfig all --config cluster.yaml\n\n由于service account的密钥是以rsa密钥对形式生成，所以没有过期时间。\n如无必要，千万不要生成重新生成sa密钥。因为sa密钥关联到一切系统pod内的进程访问api server时的认证。\n如果更新了sa，则需要先重新生成这些pod加截的token，再删除这些pod之后，重新加载token文件。\n\n</code></pre>\n<h4><a href=\"http://t.zoukankan.com/qinghe123-p-12582393.html\">kubeadm安装的k8s集群证书过期处理</a></h4>\n<h4><a href=\"https://blog.csdn.net/swan_tang/article/details/115755311\">Unable to connect to the server: x509: certificate has expired or is not yet valid</a></h4>\n<pre><code>1.  登录master服务器，进入 `/etc/kubernetes/` 查看证书，确认证书有效期：openssl x509 -in apiserver.crt -noout -text |grep ' Not '\n2.  备份 `/etc/kubernetes/pki` 目录下的所有文件\n3.* 手动更新证书 `kubeadm alpha certs renew all`\n4.  查看证书有效期是否更新\n5.  在master节点上将/etc/kubernetes目录下的所有配置文件备份\n6.  更新用户配置：执行下面多个命令\n\nkubeadm alpha kubeconfig user --client-name=admin\nkubeadm alpha kubeconfig user --org system:masters --client-name kubernetes-admin  > /etc/kubernetes/admin.conf\nkubeadm alpha kubeconfig user --client-name system:kube-controller-manager > /etc/kubernetes/controller-manager.conf\nkubeadm alpha kubeconfig user --org system:nodes --client-name system:node:$(hostname) > /etc/kubernetes/kubelet.conf\nkubeadm alpha kubeconfig user --client-name system:kube-scheduler > /etc/kubernetes/scheduler.conf\n\n7.* 用更新后的admin.conf替换/root/.kube/config文件\n8.  更新后，把master 节点服务器的 home目录下的 .kube 文件夹 复制到本机的/home/用户目录下\n9.  重启所有master节点上的apiserver和scheduler两个系统组件\n10. 本机执行kubectl 命令\n\n</code></pre>\n<h2>问题的检查确认及必要准备</h2>\n<ol>\n<li>\n<p>登录 master 节点</p>\n</li>\n<li>\n<p>执行命令，查看证书有效期（简单查看）</p>\n</li>\n</ol>\n<pre><code>openssl x509 -in /etc/kubernetes/pki/apiserver.crt -noout -text |grep ' Not '\n</code></pre>\n<ol start=\"3\">\n<li>详细查看</li>\n</ol>\n<pre><code>cd /etc/kubernetes\nls\n</code></pre>\n<pre><code>cd /etc/kubernetes/pki\nopenssl x509 -in apiserver.crt -noout -text |grep ' Not '\nkubeadm alpha certs check-expiration\n</code></pre>\n<p>详细结果</p>\n<pre><code>[root@k8s-m1 ~]# openssl x509 -in /etc/kubernetes/pki/apiserver.crt -noout -text |grep ' Not '\n            Not Before: Jul  8 03:24:35 2020 GMT\n            Not After : Jul  8 03:24:35 2021 GMT\n</code></pre>\n<pre><code>CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED\nadmin.conf                 Jul 08, 2021 03:24 UTC   &#x3C;invalid>                               no      \napiserver                  Jul 08, 2021 03:24 UTC   &#x3C;invalid>       ca                      no      \napiserver-etcd-client      Jul 08, 2021 03:24 UTC   &#x3C;invalid>       etcd-ca                 no      \napiserver-kubelet-client   Jul 08, 2021 03:24 UTC   &#x3C;invalid>       ca                      no      \ncontroller-manager.conf    Jul 08, 2021 03:24 UTC   &#x3C;invalid>                               no      \netcd-healthcheck-client    Jul 08, 2021 03:24 UTC   &#x3C;invalid>       etcd-ca                 no      \netcd-peer                  Jul 08, 2021 03:24 UTC   &#x3C;invalid>       etcd-ca                 no      \netcd-server                Jul 08, 2021 03:24 UTC   &#x3C;invalid>       etcd-ca                 no      \nfront-proxy-client         Jul 08, 2021 03:24 UTC   &#x3C;invalid>       front-proxy-ca          no      \nscheduler.conf             Jul 08, 2021 03:24 UTC   &#x3C;invalid>                               no      \n\nCERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED\nca                      Jul 06, 2030 03:24 UTC   8y              no      \netcd-ca                 Jul 06, 2030 03:24 UTC   8y              no      \nfront-proxy-ca          Jul 06, 2030 03:24 UTC   8y              no      \n</code></pre>\n<blockquote>\n<p><code>ca</code>, <code>etcd-ca</code>, <code>front-proxy-ca</code> 这三个证书有效期8年，并未过期。其他 10 个证书已经过期。</p>\n</blockquote>\n<ol start=\"4\">\n<li>备份证书 及 k8s 配置文件</li>\n</ol>\n<pre><code>cd /\ncd ~\nmkdir backup\ncp -r /etc/kubernetes ./backup/etc_k8s\nls ./backup/etc_k8s/\n</code></pre>\n<ol start=\"5\">\n<li>\n<p>登录 k8s 工作节点</p>\n</li>\n<li>\n<p>查找 dbpg pod</p>\n</li>\n</ol>\n<pre><code>docker ps\n</code></pre>\n<p>找到 <code>k8s_dbpg-container</code></p>\n<ol start=\"7\">\n<li>进入容器</li>\n</ol>\n<pre><code>docker exec -it d7a /bin/bash\n</code></pre>\n<ol start=\"8\">\n<li>备份数据库</li>\n</ol>\n<pre><code>cd script\npg_dump -h dbpg -U postgres archellis > 20210717.yunzhi.bak\n</code></pre>\n<ol start=\"9\">\n<li>退出容器</li>\n</ol>\n<pre><code>exit\n</code></pre>\n<ol start=\"10\">\n<li>检查备份文件</li>\n</ol>\n<pre><code>cd ~/projects/caskbank/database/script\nls\n</code></pre>\n<ol start=\"11\">\n<li>异地备份</li>\n</ol>\n<pre><code>scp 20210717.yunzhi.bak 172.17.64.152:~/projects/dbdump/\n</code></pre>\n<h2>问题解决的实际操作</h2>\n<ol>\n<li>手动更新证书</li>\n</ol>\n<pre><code>cd /etc/kubernetes/pki\nkubeadm alpha certs renew all\n</code></pre>\n<ol start=\"2\">\n<li>检查证书有效期</li>\n</ol>\n<pre><code>openssl x509 -in apiserver.crt -noout -text |grep ' Not '\nkubeadm alpha certs check-expiration\n</code></pre>\n<pre><code>[root@k8s-m1 pki]# openssl x509 -in apiserver.crt -noout -text |grep ' Not '\n            Not Before: Jul  8 03:24:35 2020 GMT\n            Not After : Jul 17 01:01:13 2022 GMT\n</code></pre>\n<pre><code>CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED\nadmin.conf                 Jul 17, 2022 01:01 UTC   364d                                    no      \napiserver                  Jul 17, 2022 01:01 UTC   364d            ca                      no      \napiserver-etcd-client      Jul 17, 2022 01:01 UTC   364d            etcd-ca                 no      \napiserver-kubelet-client   Jul 17, 2022 01:01 UTC   364d            ca                      no      \ncontroller-manager.conf    Jul 17, 2022 01:01 UTC   364d                                    no      \netcd-healthcheck-client    Jul 17, 2022 01:01 UTC   364d            etcd-ca                 no      \netcd-peer                  Jul 17, 2022 01:01 UTC   364d            etcd-ca                 no      \netcd-server                Jul 17, 2022 01:01 UTC   364d            etcd-ca                 no      \nfront-proxy-client         Jul 17, 2022 01:01 UTC   364d            front-proxy-ca          no      \nscheduler.conf             Jul 17, 2022 01:01 UTC   364d                                    no      \n\nCERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED\nca                      Jul 06, 2030 03:24 UTC   8y              no      \netcd-ca                 Jul 06, 2030 03:24 UTC   8y              no      \nfront-proxy-ca          Jul 06, 2030 03:24 UTC   8y              no   \n</code></pre>\n<ol start=\"3\">\n<li>更新用户配置</li>\n</ol>\n<pre><code>cd /etc/kubernetes\n\nkubeadm alpha kubeconfig user --client-name=admin\nkubeadm alpha kubeconfig user --org system:masters --client-name kubernetes-admin  > /etc/kubernetes/admin.conf\nkubeadm alpha kubeconfig user --client-name system:kube-controller-manager > /etc/kubernetes/controller-manager.conf\nkubeadm alpha kubeconfig user --org system:nodes --client-name system:node:$(hostname) > /etc/kubernetes/kubelet.conf\nkubeadm alpha kubeconfig user --client-name system:kube-scheduler > /etc/kubernetes/scheduler.conf\n</code></pre>\n<ol start=\"4\">\n<li>master 节点 config</li>\n</ol>\n<pre><code>cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config\n</code></pre>\n<ol start=\"5\">\n<li>登录 <code>worker</code> 节点</li>\n</ol>\n<blockquote>\n<p>将master节点上的 <code>$HOME/.kube/config</code> 文件拷贝到 <code>worker</code> 节点对应的文件中</p>\n</blockquote>\n<pre><code>scp k8s-m1:~/.kube/config $HOME/.kube\nchown $(id -u):$(id -g) $HOME/.kube/config\n</code></pre>\n<ol start=\"6\">\n<li>重启 master 节点服务（命令执行失败）</li>\n</ol>\n<pre><code>systemctl restart kube-apiserver\nsystemctl restart kube-scheduler\n</code></pre>\n<h2>重新配置 LENS</h2>\n<ol>\n<li>检查配置文件中的公网地址</li>\n</ol>\n<pre><code>cd ~\ncat ./kubeadm-config.yaml\n</code></pre>\n<pre><code>apiVersion: kubeadm.k8s.io/v1beta2\nkind: ClusterConfiguration\nkubernetesVersion: v1.18.3\nimageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers\n\n#master地址\ncontrolPlaneEndpoint: \"********:6443\"\nnetworking:\n  serviceSubnet: \"10.96.0.0/16\"\n\n  #k8s容器组所在的网段\n  podSubnet: \"10.20.0.1/16\"\n  dnsDomain: \"cluster.local\"\n\n# 为了让证书包含公网IP，从而允许从外网访问集群\napiServer:\n  certSANs:       #填写所有kube-apiserver节点的hostname、IP、VIP\n  - k8s-m1        #请替换为hostname\n  - ********   #请替换为公网\n  - ********   #请替换为私网\n  - 10.96.0.1     #不要替换，此IP是API的集群地址，部分服务会用到\n</code></pre>\n<ol start=\"2\">\n<li>检查</li>\n</ol>\n<pre><code>cd ~\ncat ~/.kube/config\n</code></pre>\n<pre><code>apiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: LS......LQo=\n    server: https://***************:6443\n  name: kubernetes\n  \ncontexts:\n- context:\n    cluster: kubernetes\n    user: kubernetes-admin\n  name: kubernetes-admin@kubernetes\ncurrent-context: kubernetes-admin@kubernetes\n\nkind: Config\npreferences: {}\nusers:\n- name: kubernetes-admin\n  user:\n    client-certificate-data: LS...........LQo=\n    client-key-data: LS.........LQo=\n</code></pre>\n<ol start=\"3\">\n<li>\n<p>复制上面的 config 内容</p>\n</li>\n<li>\n<p>并修改其中的 ***********:6443 ， 修改为公网地址</p>\n</li>\n<li>\n<p>修改 context 的 name，和 current-context（否则，LENS无法添加）</p>\n</li>\n</ol>\n<blockquote>\n<p>比如，改为：kubernetes-admin@kubernetesCMCC</p>\n</blockquote>\n<ol start=\"6\">\n<li>进入 LENS ，Add Cluster，paste config</li>\n</ol>\n<h1>命名空间删除失败</h1>\n<h2>现象</h2>\n<p>命名空间没有消失，状态始终在 <code>Terminating</code></p>\n<h2>参考</h2>\n<ul>\n<li><a href=\"https://q.cnblogs.com/q/125837/\">K8s 无法删除 namespace 的问题</a></li>\n<li><a href=\"https://blog.csdn.net/wangchao_cn/article/details/112687355\">k8s 强制删除命名空间namespace</a></li>\n</ul>\n<h2>解决办法</h2>\n<p>执行以下命令</p>\n<pre><code>kubectl get namespace caskbank-demo-ns -o json \\\n            | tr -d \"\\n\" | sed \"s/\\\"finalizers\\\": \\[[^]]\\+\\]/\\\"finalizers\\\": []/\" \\\n            | kubectl replace --raw /api/v1/namespaces/caskbank-demo-ns/finalize -f -\n</code></pre>\n<pre><code>kubectl get namespace [name of namespace] -o json \\\n            | tr -d \"\\n\" | sed \"s/\\\"finalizers\\\": \\[[^]]\\+\\]/\\\"finalizers\\\": []/\" \\\n            | kubectl replace --raw /api/v1/namespaces/[name of namespace]/finalize -f -\n</code></pre>\n<h2>特别说明</h2>\n<p>上述问题，一个是证书过期的问题，一个是命名空间删除的问题。这两个问题，可能是连锁反应。\n最终，还是重启的 master 和 worker 节点服务器，集群才恢复正常。</p>"}},
    "staticQueryHashes": ["1280648994","3159585216"]}